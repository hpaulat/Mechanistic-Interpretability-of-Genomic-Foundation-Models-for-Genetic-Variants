{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3360614",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import torch\n",
    "from sklearn import linear_model\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import StratifiedKFold, cross_validate\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "\n",
    "# This notebook assumes execution from the project root.\n",
    "# It explicitly sets cwd to external/genomic-FM so GV-Rep loaders work.\n",
    "\n",
    "os.chdir(\"../external/genomic-FM\")\n",
    "sys.path.append(\".\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e89a347b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['model_name', 'seq_len', 'pooling', 'layer', 'labels', 'ref_embeddings', 'alt_embeddings', 'delta_embeddings', 'ref_sequences', 'alt_sequences'])\n",
      "Embeddings shape: torch.Size([155, 1024])\n",
      "Labels shape: 155\n",
      "Encoded labels: [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "path = \"root/data/clinvar_embeddings__n155__len1024__layer-1__maskedmean.pt\"\n",
    "payload = torch.load(path, map_location=\"cpu\")\n",
    "\n",
    "print(payload.keys())\n",
    "print(\"Embeddings shape:\", payload[\"delta_embeddings\"].shape)\n",
    "print(\"Labels shape:\", len(payload[\"labels\"]))\n",
    "\n",
    "X = payload[\"delta_embeddings\"]\n",
    "labels = payload[\"labels\"]\n",
    "\n",
    "#Encode labels (Classes 1,2,3 --> 0 and Classes 3,4,5 --> 1)\n",
    "# = [0 if label in [\"Class 1\", \"Class 2\", \"Class 3\"] else 1 for label in labels]\n",
    "\n",
    "mask = np.isin(labels, [\"Class 1\", \"Class 5\"])\n",
    "y = [0 if label == \"Class 1\" else 1 for label in labels if label in [\"Class 1\", \"Class 5\"]]\n",
    "X = X[mask]\n",
    "print(\"Encoded labels:\", y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4103c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.7237878787878789 +/- 0.04456606408414642\n",
      "Acc:     0.6940711462450594 +/- 0.07514456688263174\n",
      "F1:      0.703091111786764 +/- 0.08076593303148627\n"
     ]
    }
   ],
   "source": [
    "clf = make_pipeline(\n",
    "    StandardScaler(),\n",
    "    PCA(n_components=50),  # optional: reduce dimensionality\n",
    "    LogisticRegression(\n",
    "        l1_ratio=0,\n",
    "        C=0.1,               # smaller = stronger regularization; start 0.1 or 0.01\n",
    "        solver=\"liblinear\",  # good for small datasets\n",
    "        max_iter=5000\n",
    "    )\n",
    ")\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "\n",
    "res = cross_validate(\n",
    "    clf, X, y,\n",
    "    cv=cv,\n",
    "    scoring=[\"roc_auc\", \"accuracy\", \"f1\"],\n",
    "    return_train_score=False\n",
    ")\n",
    "\n",
    "print(\"ROC-AUC:\", res[\"test_roc_auc\"].mean(), \"+/-\", res[\"test_roc_auc\"].std())\n",
    "print(\"Acc:    \", res[\"test_accuracy\"].mean(), \"+/-\", res[\"test_accuracy\"].std())\n",
    "print(\"F1:     \", res[\"test_f1\"].mean(), \"+/-\", res[\"test_f1\"].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0860dbd4",
   "metadata": {},
   "source": [
    "This tells us there is enough signal in the embeddings to somewhat discern the two extremes. The nucleotide-transformer last-layer representations encode information that distinguishes benign from pathogenic variants. ClinVar classes dilute separability due to level ambiguity, not model failure.\n",
    "\n",
    "PCA also improves performance a bit, showing how discriminative information lives in a small subspace, and that most dimensions are noise or irrelevant variation. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a5d35747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embeddings from: root/data/clinvar_pooled_embeddings__n155__bp3000__tok505__layers10.pt\n",
      "dict_keys(['model_name', 'bp_window_len', 'token_max_length', 'pooling', 'layers', 'labels', 'embeddings_by_layer'])\n",
      "Size of E: torch.Size([310, 1024])\n"
     ]
    }
   ],
   "source": [
    "path = \"root/data/clinvar_pooled_embeddings__n155__bp3000__tok505__layers10.pt\"\n",
    "payload = torch.load(path, map_location=\"cpu\")\n",
    "\n",
    "print(\"Loading embeddings from:\", path)\n",
    "print(payload.keys())\n",
    "\n",
    "layers = payload[\"layers\"]\n",
    "labels = np.array(payload[\"labels\"])\n",
    "n = len(labels)  # number of variants (N)\n",
    "\n",
    "# pick a layer you want\n",
    "layer = 28  # e.g., last layer\n",
    "E = payload[\"embeddings_by_layer\"][layer]  # shape (2N, 1024), torch.Tensor\n",
    "print(\"Size of E:\", E.shape)\n",
    "\n",
    "# split REF and ALT\n",
    "ref = E[:n].numpy()      # (N, 1024)\n",
    "alt = E[n:].numpy()      # (N, 1024)\n",
    "\n",
    "# delta\n",
    "X = alt - ref            # (N, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3eaa3f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using only Class 1 and Class 5 samples: 114 out of 155\n",
      "y shape before encoding: (155,)\n",
      "X shape: (114, 1024)\n",
      "y counts: 114 with 60 positives\n",
      "Len of record = 1024\n"
     ]
    }
   ],
   "source": [
    "mask = np.isin(labels, [\"Class 1\", \"Class 5\"])\n",
    "print(\"Using only Class 1 and Class 5 samples:\", np.sum(mask), \"out of\", n)\n",
    "X_bin = X[mask]\n",
    "print(\"y shape before encoding:\", labels.shape)\n",
    "y_bin = (labels[mask] == \"Class 5\").astype(int)  # Class 1 -> 0, Class 5 -> 1\n",
    "\n",
    "print(\"X shape:\", X_bin.shape)\n",
    "print(\"y counts:\", len(y_bin), \"with\", np.sum(y_bin), \"positives\")\n",
    "print(\"Len of record =\", X_bin[0].shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8af71438",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC-AUC: 0.864 +/- 0.045\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"lr\", LogisticRegression(max_iter=5000, class_weight=\"balanced\"))\n",
    "])\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=0)\n",
    "auc = cross_val_score(clf, X_bin, y_bin, cv=cv, scoring=\"roc_auc\")\n",
    "\n",
    "print(f\"ROC-AUC: {auc.mean():.3f} +/- {auc.std():.3f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mechanistic_interpretability",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
